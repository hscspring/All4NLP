{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_crfsuite import metrics\n",
    "import sklearn_crfsuite\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./emerging_entities_17/wnut17train.conll\"\n",
    "val_file = \"./emerging_entities_17/emerging.dev.conll\"\n",
    "test_file = \"./emerging_entities_17/emerging.test.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@paulwalk\tO\r\n",
      "It\tO\r\n",
      "'s\tO\r\n",
      "the\tO\r\n",
      "view\tO\r\n",
      "from\tO\r\n",
      "where\tO\r\n",
      "I\tO\r\n",
      "'m\tO\r\n",
      "living\tO\r\n",
      "for\tO\r\n",
      "two\tO\r\n",
      "weeks\tO\r\n",
      ".\tO\r\n",
      "Empire\tB-location\r\n",
      "State\tI-location\r\n",
      "Building\tI-location\r\n",
      "=\tO\r\n",
      "ESB\tB-location\r\n",
      ".\tO\r\n",
      "Pretty\tO\r\n",
      "bad\tO\r\n",
      "storm\tO\r\n",
      "here\tO\r\n",
      "last\tO\r\n",
      "evening\tO\r\n",
      ".\tO\r\n",
      "\t\r\n",
      "From\tO\r\n",
      "Green\tO\r\n",
      "Newsfeed\tO\r\n",
      ":\tO\r\n",
      "AHFA\tB-group\r\n",
      "extends\tO\r\n",
      "deadline\tO\r\n",
      "for\tO\r\n",
      "Sage\tO\r\n",
      "Award\tO\r\n",
      "to\tO\r\n",
      "Nov\tO\r\n",
      ".\tO\r\n",
      "5\tO\r\n",
      "http://tinyurl.com/24agj38\tO\r\n",
      "\t\r\n",
      "Pxleyes\tB-corporation\r\n",
      "Top\tO\r\n",
      "50\tO\r\n",
      "Photography\tO\r\n",
      "Contest\tO\r\n",
      "Pictures\tO\r\n"
     ]
    }
   ],
   "source": [
    "!head -50 ./emerging_entities_17/wnut17train.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_dataset(file: str, sep: str = \"\\t\"):\n",
    "    sent_bio = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            # remove the blank token at the beginning or end of a sentence\n",
    "            line = line.strip()\n",
    "            # continue for \"\"\n",
    "            if not line:\n",
    "                postags = nltk.pos_tag([w for (w,l) in sent_bio])\n",
    "                data = [item + (sent_bio[i][1], ) for i, item in enumerate(postags)]\n",
    "                yield data\n",
    "                sent_bio = []\n",
    "                continue\n",
    "            word, labels = line.split(sep)\n",
    "            # choose the last label\n",
    "            label = labels.split(\",\")[-1]\n",
    "            sent_bio.append((word, label))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3394 1009 1287\n",
      "[('@paulwalk', 'VB', 'O'), ('It', 'PRP', 'O'), (\"'s\", 'VBZ', 'O'), ('the', 'DT', 'O'), ('view', 'NN', 'O'), ('from', 'IN', 'O'), ('where', 'WRB', 'O'), ('I', 'PRP', 'O'), (\"'m\", 'VBP', 'O'), ('living', 'VBG', 'O'), ('for', 'IN', 'O'), ('two', 'CD', 'O'), ('weeks', 'NNS', 'O'), ('.', '.', 'O'), ('Empire', 'NNP', 'B-location'), ('State', 'NNP', 'I-location'), ('Building', 'NNP', 'I-location'), ('=', 'NNP', 'O'), ('ESB', 'NNP', 'B-location'), ('.', '.', 'O'), ('Pretty', 'NNP', 'O'), ('bad', 'JJ', 'O'), ('storm', 'NN', 'O'), ('here', 'RB', 'O'), ('last', 'JJ', 'O'), ('evening', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "train_sents = list(read_file_to_dataset(train_file))\n",
    "val_sents = list(read_file_to_dataset(val_file))\n",
    "test_sents = list(read_file_to_dataset(test_file))\n",
    "\n",
    "print(len(train_sents), len(val_sents), len(test_sents))\n",
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B-corporation',\n",
       " 'B-creative-work',\n",
       " 'B-group',\n",
       " 'B-location',\n",
       " 'B-person',\n",
       " 'B-product',\n",
       " 'I-corporation',\n",
       " 'I-creative-work',\n",
       " 'I-group',\n",
       " 'I-location',\n",
       " 'I-person',\n",
       " 'I-product',\n",
       " 'O'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set([lab for (t, p, lab)  in itertools.chain(*train_sents)])\n",
    "print(len(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the lengths\n",
    "lengths = []\n",
    "for sen in train_sents:\n",
    "    lengths.append(len(sen))\n",
    "plt.hist(lengths);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's the same as the reference\n",
    "# we could modify the features\n",
    "def word2features(sent, i):\n",
    "    \n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    # add more word features\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[-1:]': word[-1:],\n",
    "        'word[1:]': word[1:],\n",
    "        'word[2:]': word[2:],\n",
    "        'word[3:]': word[3:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        # Indicate that it is the 'beginning of a document'\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        # Features for words that are not at the end of a document\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-location', 'I-location', 'B-group', 'B-corporation', 'B-person', 'B-creative-work', 'B-product', 'I-person', 'I-creative-work', 'I-corporation', 'I-group', 'I-product']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1352670611299168"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "print(labels)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['B-corporation', 'I-corporation', 'B-creative-work', 'I-creative-work', 'B-group', 'I-group', 'B-location', 'I-location', 'B-person', 'I-person', 'B-product', 'I-product'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation      0.200     0.011     0.021        89\n",
      "  I-corporation      0.000     0.000     0.000        32\n",
      "B-creative-work      0.000     0.000     0.000       131\n",
      "I-creative-work      0.167     0.023     0.041       172\n",
      "        B-group      0.308     0.023     0.043       175\n",
      "        I-group      0.125     0.015     0.027        66\n",
      "     B-location      0.381     0.316     0.346       117\n",
      "     I-location      0.417     0.303     0.351        33\n",
      "       B-person      0.491     0.150     0.230       373\n",
      "       I-person      0.456     0.243     0.317       107\n",
      "      B-product      0.750     0.029     0.056       103\n",
      "      I-product      0.167     0.016     0.029        62\n",
      "\n",
      "      micro avg      0.391     0.098     0.157      1460\n",
      "      macro avg      0.288     0.094     0.122      1460\n",
      "   weighted avg      0.333     0.098     0.135      1460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all labels in dataset\n",
    "def get_labels(train_sents, without_bio: bool = False):\n",
    "    ls = set()\n",
    "    for sen in train_sents:\n",
    "        for token in sen:\n",
    "            label = token[2]\n",
    "            # without B I O\n",
    "            if without_bio and label != \"O\":\n",
    "                label = label[2:]\n",
    "            ls.add(label)\n",
    "    return list(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset for training and testing\n",
    "def make_dataset(dataset, label_dict, without_bio: bool = False):\n",
    "    sents_sm = []\n",
    "    labels_sm = []\n",
    "    for sent_item in dataset:\n",
    "        sent_sm = []\n",
    "        label_sm = []\n",
    "        for token in sent_item:\n",
    "            sent_sm.append(token[0])\n",
    "            tag = token[2]\n",
    "            if without_bio and tag != \"O\":\n",
    "                tag = token[2][2:]\n",
    "            label = label_dict.get(tag)\n",
    "            label_sm.append(label)\n",
    "        sents_sm.append(sent_sm)\n",
    "        labels_sm.append(label_sm)\n",
    "    return sents_sm, labels_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tokens_to_inds(sentence, word_2_id):\n",
    "    return [word_2_id.get(t, word_2_id[\"<unk>\"]) for t in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_for_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "    return [pad_token]*window_size + sentence + [pad_token]*window_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(data, window_size, word_2_id, num_labels):\n",
    "    \"\"\"\n",
    "    For some chunk of sentences and labels\n",
    "        -add winow padding\n",
    "        -pad for lengths using pad_sequence\n",
    "        -convert our labels to one-hots\n",
    "        -return padded inputs, one-hot labels, and lengths\n",
    "    \"\"\"\n",
    "    \n",
    "    x_s, y_s = zip(*data)\n",
    "\n",
    "    # deal with input sentences as we've seen\n",
    "    window_padded = [convert_tokens_to_inds(pad_sentence_for_window(sentence, window_size), word_2_id)\n",
    "                                                                                  for sentence in x_s]\n",
    "    # append zeros to each list of token ids in batch so that they are all the same length\n",
    "    padded = nn.utils.rnn.pad_sequence([torch.LongTensor(t) for t in window_padded], batch_first=True)\n",
    "    \n",
    "    # directily add labels\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    for y in y_s:\n",
    "        lengths.append(len(y))\n",
    "        label = torch.LongTensor(y)\n",
    "        labels.append(label)\n",
    "    padded_labels = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    return padded.long(), padded_labels, torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'person': 1,\n",
       " 'location': 2,\n",
       " 'corporation': 3,\n",
       " 'creative-work': 4,\n",
       " 'product': 5,\n",
       " 'group': 6}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels for softmax classifier\n",
    "labels = get_labels(train_sents, True)\n",
    "label2id = dict(zip(list(sorted(labels, key=lambda x: x[1:])), range(len(labels))))\n",
    "id2label = dict(zip(label2id.values(), label2id.keys()))\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents_sm, train_labels_sm = make_dataset(train_sents, label2id, True)\n",
    "val_sents_sm, val_labels_sm = make_dataset(val_sents, label2id, True)\n",
    "test_sents_sm, test_labels_sm = make_dataset(test_sents, label2id, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14880"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = [\"<pad>\", \"<unk>\"]\n",
    "id2word += list(set(itertools.chain(*train_sents_sm)))\n",
    "word2id = {w:i for i,w in enumerate(id2word)}\n",
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(train_sents_sm, train_labels_sm)), \n",
    "    batch_size=2, shuffle=True, \n",
    "    collate_fn=partial(my_collate, window_size=2, word_2_id=word2id, num_labels=len(label2id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inputs',\n",
      " tensor([[    0,     0,  4003,  3847, 11569,  6764, 10183, 10680, 13454,  4946,\n",
      "         12455, 13327,  4003, 11583,  1135,  3852,  8010, 14237,  6802, 10189,\n",
      "          4321, 14643, 12145,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    0,     0,  7328,  3276, 13232, 13758,  4737, 11481,  1006, 14479,\n",
      "         10680, 14082,  1135,  6444,  4711,  8511,  5587,  8511,  3298, 12145,\n",
      "         10504,  2834,  6153,  9990,  7869,  4654,  8881, 12145,     0,     0]]),\n",
      " torch.Size([2, 30]))\n",
      "('labels',\n",
      " tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0, -1, -1, -1, -1, -1],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0]]),\n",
      " torch.Size([2, 26]))\n",
      "tensor([21, 26])\n"
     ]
    }
   ],
   "source": [
    "for batched_input, batched_labels, batch_lengths in example_loader:\n",
    "    pp.pprint((\"inputs\", batched_input, batched_input.size()))\n",
    "    pp.pprint((\"labels\", batched_labels, batched_labels.size()))\n",
    "    pp.pprint(batch_lengths)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWordWindowClassifier(nn.Module):\n",
    "    def __init__(self, config, vocab_size, pad_idx=0):\n",
    "        super(SoftmaxWordWindowClassifier, self).__init__()\n",
    "        self.window_size = 2*config[\"half_window\"]+1\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.hidden_dim = config[\"hidden_dim\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        self.freeze_embeddings = config[\"freeze_embeddings\"]\n",
    "        self.embed_layer = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_idx)\n",
    "        if self.freeze_embeddings:\n",
    "            self.embed_layer.weight.requires_grad = False\n",
    "        self.hidden_layer = nn.Sequential(nn.Linear(self.window_size*self.embed_dim, \n",
    "                                                    self.hidden_dim), \n",
    "                                          nn.Tanh())\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.num_classes)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        # add dropout to avoid overfitting\n",
    "        self.dropout = nn.Dropout(config[\"dropout_prob\"])\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        B, L = inputs.size()\n",
    "        token_windows = inputs.unfold(1, self.window_size, 1)\n",
    "        _, adjusted_length, _ = token_windows.size()\n",
    "        assert token_windows.size() == (B, adjusted_length, self.window_size)\n",
    "        embedded_windows = self.embed_layer(token_windows)\n",
    "        embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
    "        embedded_windows = self.dropout(embedded_windows)\n",
    "        layer_1 = self.hidden_layer(embedded_windows)\n",
    "        layer_1 = self.dropout(layer_1)\n",
    "        output = self.output_layer(layer_1)\n",
    "        output = output.view(-1, output.shape[2])\n",
    "        output = self.dropout(output)\n",
    "        output = self.log_softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels, lengths):\n",
    "    labels = labels.view(-1)\n",
    "    # mask padded labels\n",
    "    mask = (labels >= 0).float()\n",
    "    num_elems = lengths.sum().float()\n",
    "    return -torch.sum(outputs[range(outputs.shape[0]), labels] * mask) / num_elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loss_function, optimizer, model, train_data):\n",
    "    ## For each batch, we must reset the gradients\n",
    "    ## stored by the model.   \n",
    "    total_loss = 0\n",
    "    batch_num = len(train_data)\n",
    "    for batch, labels, lengths in train_data:\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # evoke model in training mode on batch\n",
    "        outputs = model(batch)\n",
    "        # compute loss w.r.t batch\n",
    "        loss = loss_function(outputs, labels, lengths)\n",
    "        # pass gradients back, startiing on loss value\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # return the total to keep track of how you did this time around\n",
    "    return total_loss / batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(loss_function, optimizer, model, test_data):\n",
    "    total_loss = 0\n",
    "    batch_num = len(test_data)\n",
    "    for batch, labels, lengths in test_data:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch)\n",
    "        loss = loss_function(outputs, labels, lengths)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, loss_function, optimizer, model, train_loader, val_loader):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(loss_function, optimizer, model, train_loader)\n",
    "        val_loss = test_epoch(loss_function, optimizer, model, val_loader)\n",
    "        if epoch % 10 == 0:\n",
    "            print(train_loss, val_loss)\n",
    "        losses.append(train_loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"batch_size\": 16,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 32,\n",
    "          \"hidden_dim\": 32,\n",
    "          \"num_classes\": len(label2id),\n",
    "          \"freeze_embeddings\": False,\n",
    "          \"dropout_prob\": 0.5\n",
    "         }\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20\n",
    "model = SoftmaxWordWindowClassifier(config, len(word2id))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(train_sents_sm, train_labels_sm)), \n",
    "    batch_size=config[\"batch_size\"], shuffle=True, \n",
    "    collate_fn=partial(my_collate, window_size=2, word_2_id=word2id, num_labels=len(label2id)))\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(val_sents_sm, val_labels_sm)), \n",
    "    batch_size=config[\"batch_size\"], shuffle=True, \n",
    "    collate_fn=partial(my_collate, window_size=2, word_2_id=word2id, num_labels=len(label2id)))\n",
    "labels = [id for id in id2label.keys() if id2label.get(id) != \"O\"]\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(test_sents_sm, test_labels_sm)), \n",
    "    batch_size=1, shuffle=False, \n",
    "    collate_fn=partial(my_collate, window_size=2, word_2_id=word2id, num_labels=len(label2id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8588769609379656 1.6388171650469303\n",
      "0.898311006351256 1.0224702069535851\n"
     ]
    }
   ],
   "source": [
    "history = train(num_epochs, loss_function, optimizer, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, test_loader, labels, output_report: bool = False):\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for test_instance, labs, _ in test_loader:\n",
    "        outputs = model(test_instance)\n",
    "        y_pred = torch.argmax(outputs, dim=1).detach().numpy()\n",
    "        y_preds.append(y_pred.tolist())\n",
    "        y_trues.append(labs.numpy().tolist()[0])\n",
    "\n",
    "    print(metrics.flat_f1_score(y_trues, y_preds, average='weighted', labels=labels))\n",
    "    if output_report:\n",
    "        print(metrics.flat_classification_report(y_trues, y_preds, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014403366892435657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.022     0.008     0.012       480\n",
      "           2      0.005     0.013     0.008       150\n",
      "           3      0.005     0.033     0.009       121\n",
      "           4      0.013     0.059     0.021       303\n",
      "           5      0.006     0.109     0.012       165\n",
      "           6      0.010     0.245     0.019       241\n",
      "\n",
      "   micro avg      0.009     0.072     0.016      1460\n",
      "   macro avg      0.010     0.078     0.013      1460\n",
      "weighted avg      0.013     0.072     0.014      1460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(model, test_loader, labels, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4410284550536967 1.708241581916809\n",
      "1.560937524401526 2.139604428783059\n",
      "0.016890647072350433\n",
      "0.9663480002555489 1.0672624865546823\n",
      "0.9370820693007098 1.1078242929652333\n",
      "0.02049186248014537\n",
      "0.9484141631305497 1.0670955423265696\n",
      "0.8341157732994904 1.1148025076836348\n",
      "0.023277226161830457\n",
      "0.9893727131852521 0.9949080757796764\n",
      "0.7695537178729062 1.0123037388548255\n",
      "0.036716223301551006\n",
      "1.0412188832748663 1.010098141618073\n",
      "0.7901834747601003 0.9805597104132175\n",
      "0.03349212048065159\n",
      "1.4221635362911673 1.1958199199289083\n",
      "0.8702562367412406 0.9743502447381616\n",
      "0.03975807180265422\n"
     ]
    }
   ],
   "source": [
    "# learning_rate\n",
    "config = {\"batch_size\": 16,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 32,\n",
    "          \"hidden_dim\": 32,\n",
    "          \"num_classes\": len(label2id),\n",
    "          \"freeze_embeddings\": False,\n",
    "          \"dropout_prob\": 0.5\n",
    "         }\n",
    "num_epochs = 20\n",
    "for learning_rate in [0.5, 0.1, 0.05, 0.01, 0.005, 0.001]:\n",
    "    model = SoftmaxWordWindowClassifier(config, len(word2id))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    history = train(num_epochs, loss_function, optimizer, model, train_loader, val_loader)\n",
    "    print_score(model, test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dim:  8\n",
      "1.4760623784132407 1.0877766348421574\n",
      "0.8945051778650059 1.0170803032815456\n",
      "0.014162787385496645\n",
      "Embedding dim:  16\n",
      "1.4133415977719803 1.0690827462822199\n",
      "0.8776822509899945 0.9964117547497153\n",
      "0.018244525124492025\n",
      "Embedding dim:  32\n",
      "1.4524243331291307 1.158347962424159\n",
      "0.8690206109078278 0.9839324643835425\n",
      "0.028954863156406573\n",
      "Embedding dim:  64\n",
      "1.4002246901462896 1.1191635075956583\n",
      "0.8541542006210542 1.040855348110199\n",
      "0.01936489972611207\n",
      "Embedding dim:  128\n",
      "1.3341651349000527 1.0886969985440373\n",
      "0.8346883106119756 1.0053897723555565\n",
      "0.0334319894330069\n"
     ]
    }
   ],
   "source": [
    "# embed_dim\n",
    "config = {\"batch_size\": 16,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 32,\n",
    "          \"hidden_dim\": 32,\n",
    "          \"num_classes\": len(label2id),\n",
    "          \"freeze_embeddings\": False,\n",
    "          \"dropout_prob\": 0.5\n",
    "         }\n",
    "num_epochs = 20\n",
    "for embed_dim in [8, 16, 32, 64, 128]:\n",
    "    print(\"Embedding dim: \", embed_dim)\n",
    "    config[\"embed_dim\"] = embed_dim\n",
    "    model = SoftmaxWordWindowClassifier(config, len(word2id))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    history = train(num_epochs, loss_function, optimizer, model, train_loader, val_loader)\n",
    "    print_score(model, test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden dim:  8\n",
      "1.4175758417783209 1.2223599776625633\n",
      "0.8804250116079626 0.9924459545873106\n",
      "0.03233573211758958\n",
      "Hidden dim:  16\n",
      "1.4871680949215598 1.1335263084620237\n",
      "0.8771239267268651 1.0420225774869323\n",
      "0.015494697653027044\n",
      "Hidden dim:  32\n",
      "1.3766505175353216 1.1125110322609544\n",
      "0.8671806449061829 0.9882329208776355\n",
      "0.02842914492782242\n",
      "Hidden dim:  64\n",
      "1.336010734520048 1.0632217479869723\n",
      "0.861740357719117 0.9732221411541104\n",
      "0.026659755194059456\n",
      "Hidden dim:  128\n",
      "1.2550609842152662 1.0291369846090674\n",
      "0.8683240122638398 0.9885111544281244\n",
      "0.022806557998367488\n"
     ]
    }
   ],
   "source": [
    "# hidden_dim\n",
    "config = {\"batch_size\": 16,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 32,\n",
    "          \"hidden_dim\": 32,\n",
    "          \"num_classes\": len(label2id),\n",
    "          \"freeze_embeddings\": False,\n",
    "          \"dropout_prob\": 0.5\n",
    "         }\n",
    "num_epochs = 20\n",
    "for hidden_dim in [8, 16, 32, 64, 128]:\n",
    "    print(\"Hidden dim: \", hidden_dim)\n",
    "    config[\"hidden_dim\"] = hidden_dim\n",
    "    model = SoftmaxWordWindowClassifier(config, len(word2id))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    history = train(num_epochs, loss_function, optimizer, model, train_loader, val_loader)\n",
    "    print_score(model, test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num epochs:  1\n",
      "1.4438380467499925 1.1052329828962684\n",
      "0.011253401801668726\n",
      "Num epochs:  5\n",
      "1.4099277935117622 1.2587079666554928\n",
      "0.01381389448173674\n",
      "Num epochs:  10\n",
      "1.4859351185565823 1.2159945983439684\n",
      "0.016440546845950553\n",
      "Num epochs:  20\n",
      "1.5102287841514803 1.199783032760024\n",
      "0.8725363749293654 1.0607517715543509\n",
      "0.024727275920377267\n",
      "Num epochs:  50\n",
      "1.470889863553741 1.1230453215539455\n",
      "0.8784864687583815 1.0052653532475233\n",
      "0.8309886200886937 1.0564784109592438\n",
      "0.8058597495858099 1.0399972451850772\n",
      "0.7837466368093177 1.0417290180921555\n",
      "0.023241701029266\n"
     ]
    }
   ],
   "source": [
    "# epoches\n",
    "config = {\"batch_size\": 16,\n",
    "          \"half_window\": 2,\n",
    "          \"embed_dim\": 32,\n",
    "          \"hidden_dim\": 32,\n",
    "          \"num_classes\": len(label2id),\n",
    "          \"freeze_embeddings\": False,\n",
    "          \"dropout_prob\": 0.5\n",
    "         }\n",
    "learning_rate = 0.001\n",
    "for num_epochs in [1, 5, 10, 20, 50]:\n",
    "    print(\"Num epochs: \", num_epochs)\n",
    "    model = SoftmaxWordWindowClassifier(config, len(word2id))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    history = train(num_epochs, loss_function, optimizer, model, train_loader, val_loader)\n",
    "    print_score(model, test_loader, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
